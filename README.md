# Assessing Data Analytics

Over the past semesters, I have developed a strong, practice-oriented competency in data analytics centered on problem framing, data preparation, exploratory analysis, statistical inference, and predictive modeling.

---

## What I Know

### Data Cleaning & Preparation
- I can extract and clean datasets, handle missingness, standardize types, normalize categorical levels.  
- I apply validation checks (row counts, range checks, duplicate keys) and keep before/after metrics so changes are auditable.

### Excel Analytics
- Pivot tables: Cohort summaries, and contribution analysis.  
- Use LOOKUP to stitch datasets, then verify row counts and unmatched keys.  
- Array formulas & logicals: IF, IFS, FILTER, UNIQUE, COUNTIFS/SUMIFS chains.

### Descriptive Analysis & Baseline Visualization
- Measures of central tendency/dispersion, shape (skew), outlier diagnostics.  
- Grouped rates, proportions, mean differences with contextualized caveats.  
- Histograms, box/violin plots, time-series lines, and simple highlight tables to surface signal quickly.

---

## Where I’m Weak

### Statistical Formulas & Hypothesis Testing
- Formal test selection, assumptions, multiple testing control, and power/sample-size planning.  
- Over-interpreting descriptive differences without rigorous inference; underpowered findings.

### Predictive Analysis
- Systematic feature selection.  
- Cross-validation design (nested CV, leakage prevention) and fairness/robustness checks.

### Tableau Dashboarding & Data Storytelling
- Consistent use of color/typography hierarchy, parameter actions, Level-of-Detail expressions, mobile-aware layout, and narrative structure.

---

## What I Wish I Knew

I recognize there are likely “unknown unknowns” in my current practice. For example, I may underestimate how sensitive some metrics are to small definition changes, or how much sample selection affects apparent patterns. To surface these blind spots, I will incorporate deliberate robustness checks into my standard flow: redefine key metrics in two or three plausible ways, repeat core analyses on stratified subsamples, and compare results across adjacent time windows. I will also keep a short “assumptions and risks” note next to each project that highlights where a conclusion is most vulnerable and what evidence would strengthen it.

In communication, I occasionally provide more context than needed. While thoroughness is valuable, it can dilute the main point. I am working on making explanations more concise, keeping the focus on the decision, the minimal evidence to support it, and the practical next step.

---

## Supporting Work / Knowledge

- **Data Analytics Course 1**: [GitHub Link](https://github.com/ptphamtx/Data-Analytics-1/tree/main)

- **Data Analytics Course 2**: [GitHub Link](https://github.com/ptphamtx/Data-Analytics-2/tree/main)

- **DataCamp Courses**:  
  - Data preparation in PowerBI: [Google Drive Link](https://drive.google.com/file/d/1Y6UaGliStjpzDWfzUGV_-HXl2bQZBpa9/view?usp=sharing)  
  - Connect data in Tableau: [Google Drive Link](https://drive.google.com/file/d/1hakiuRdtlbkIRXp-LZ0jdprRQ0mKjz3Y/view?usp=sharing)

---

## Summary

I bring strengths in cleaning and preparing messy data, building stakeholder-ready descriptive analyses, and producing fast, transparent Excel deliverables that surface signal and inform next steps. I can also stand up baseline predictive prototypes and document assumptions clearly. These competencies position me to convert raw data into decision-quality insights, with validation checks, versioned artifacts, and plain-language summaries. I am prepared to package this work into a portfolio that demonstrates full analytics and to deliver a prototype capstone project that is interpretable and tied to concrete business outcomes.
