# Assessing-Data-Analytics
Assessing Data Analytics
Over the past semesters, I have developed a strong, practice oriented competency in data analytics centered on problem framing, data preparation, exploratory analysis, statistical inference, and predictive modeling.
What I know
Data Cleaning & Preparation
•	I can extract and clean datasets, handle missingness, standardize types, normalize categorical levels
•	I apply validation checks (row counts, range checks, duplicate keys, referential “joins sanity”) and keep before/after metrics so changes are auditable.
Excel Analytics
•	Pivot tables: Cohort summaries, and contribution analysis.
•	Use LOOKUP to stitch datasets, then verify row counts and unmatched keys.
•	Array formulas & logicals: IF, IFS, FILTER, UNIQUE, COUNTIFS/SUMIFS chains
Descriptive Analysis & Baseline Visualization
•	Measures of central tendency/dispersion, shape (skew/kurtosis), outlier diagnostics.
•	Grouped rates, proportions, mean differences with contextualized caveats.
•	Histograms, box/violin plots, time-series lines, and simple highlight tables to surface signal quickly.
Where I’m weak
Statistical Formulas & Hypothesis Testing
•	Formal test selection (t-tests/ANOVA vs. nonparametrics), assumptions (normality, homoscedasticity), multiple testing control, and power/sample-size planning.
•	Over-interpreting descriptive differences without rigorous inference; underpowered findings.
Predictive Modeling Depth)
•	Systematic feature selection, cross-validation design (nested CV, leakage prevention), calibration (Platt/isotonic), and fairness/robustness checks.
•	Models that look strong in-sample but degrade in deployment, insufficient interpretability for stakeholders.
Tableau Dashboarding & Data Storytelling
•	Consistent use of color/typography hierarchy, parameter actions, Level-of-Detail expressions, mobile-aware layout, and narrative structure.
•	Non-technical audiences may miss key insights; reduces adoption of analytics outputs.
What I wish I knew
I recognize there are likely “unknown unknowns” in my current practice. For example, I may underestimate how sensitive some metrics are to small definition changes, or how much sample selection affects apparent patterns. To surface these blind spots, I will incorporate deliberate robustness checks into my standard flow: redefine key metrics in two or three plausible ways, repeat core analyses on stratified subsamples, and compare results across adjacent time windows. I will also keep a short “assumptions and risks” note next to each project that highlights where a conclusion is most vulnerable and what evidence would strengthen it.
In communication, I occasionally provide more context than needed. While thoroughness is valuable, it can dilute the main point. I am working on making explanations more concise, keeping the focus on the decision, the minimal evidence to support it, and the practical next step
Supporting work/ knowledge
•	Data Analytics Course 1: Data cleaning + preparation, pivot/XLOOKUP workflows, early Lean Six Sigma artifacts and metrics.
Repository: https://github.com/ptphamtx/Data-Analytics-1/tree/main
•	Data Analytics Course 2: Predictive modeling (classification/regression), Tableau dashboards, EDA → modeling → communication.
Repository: https://github.com/ptphamtx/Data-Analytics-2/tree/main
•	Data camp courses:
Data preparation in PowerBI: https://drive.google.com/file/d/1Y6UaGliStjpzDWfzUGV_-HXl2bQZBpa9/view?usp=sharing
Connect data in Tableau: https://drive.google.com/file/d/1hakiuRdtlbkIRXp-LZ0jdprRQ0mKjz3Y/view?usp=sharing
I bring strengths in cleaning and preparing messy data, building stakeholder-ready descriptive analyses, and producing fast, transparent Excel deliverables that surface signal and inform next steps; I can also stand up baseline predictive prototypes and document assumptions clearly. These competencies position me to convert raw data into decision-quality insights, with validation checks, versioned artifacts, and plain-language summaries. I am prepared to package this work into a portfolio that demonstrates full analytics and to deliver a prototype capstone project that is interpretable and tied to concrete business outcomes.

